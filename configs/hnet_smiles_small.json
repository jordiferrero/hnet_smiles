{
    "arch_layout": ["m4", ["T22"], "m4"],
    "d_model": [512, 768],
    "d_intermediate": [0, 2048],
    "vocab_size": 256,
    "ssm_cfg": {
        "chunk_size": 256,
        "d_conv": 4,
        "d_state": 64,
        "expand": 2
    },
    "attn_cfg": {
        "num_heads": [8, 8],
        "rotary_emb_dim": [16, 24],
        "window_size": [511, -1]
    },
    "tie_embeddings": false
}

